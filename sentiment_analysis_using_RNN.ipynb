{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentiment_analysis_using_RNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prashantRmishra/Tensorflow_learnings/blob/master/sentiment_analysis_using_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "CLJkIgS84-LK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Embedding\n",
        "from keras.layers import LSTM\n",
        "from keras.datasets import imdb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zBpC497JD0Ev",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "lets load our training data and training label(x_train,y_train) and our testing data and testing label(x_test,y_test)"
      ]
    },
    {
      "metadata": {
        "id": "7goPzcyNESqp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "(x_train,y_train),(x_test,y_test)=imdb.load_data(num_words=20000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hj7M72geEooh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "lets see how out data looks as we are concerned about only top 20000 words to train out model."
      ]
    },
    {
      "metadata": {
        "id": "buNG6TeXEnky",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3892
        },
        "outputId": "b9a26275-35b4-42d3-c447-650bba2b5e76"
      },
      "cell_type": "code",
      "source": [
        "x_train[0]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 14,\n",
              " 22,\n",
              " 16,\n",
              " 43,\n",
              " 530,\n",
              " 973,\n",
              " 1622,\n",
              " 1385,\n",
              " 65,\n",
              " 458,\n",
              " 4468,\n",
              " 66,\n",
              " 3941,\n",
              " 4,\n",
              " 173,\n",
              " 36,\n",
              " 256,\n",
              " 5,\n",
              " 25,\n",
              " 100,\n",
              " 43,\n",
              " 838,\n",
              " 112,\n",
              " 50,\n",
              " 670,\n",
              " 2,\n",
              " 9,\n",
              " 35,\n",
              " 480,\n",
              " 284,\n",
              " 5,\n",
              " 150,\n",
              " 4,\n",
              " 172,\n",
              " 112,\n",
              " 167,\n",
              " 2,\n",
              " 336,\n",
              " 385,\n",
              " 39,\n",
              " 4,\n",
              " 172,\n",
              " 4536,\n",
              " 1111,\n",
              " 17,\n",
              " 546,\n",
              " 38,\n",
              " 13,\n",
              " 447,\n",
              " 4,\n",
              " 192,\n",
              " 50,\n",
              " 16,\n",
              " 6,\n",
              " 147,\n",
              " 2025,\n",
              " 19,\n",
              " 14,\n",
              " 22,\n",
              " 4,\n",
              " 1920,\n",
              " 4613,\n",
              " 469,\n",
              " 4,\n",
              " 22,\n",
              " 71,\n",
              " 87,\n",
              " 12,\n",
              " 16,\n",
              " 43,\n",
              " 530,\n",
              " 38,\n",
              " 76,\n",
              " 15,\n",
              " 13,\n",
              " 1247,\n",
              " 4,\n",
              " 22,\n",
              " 17,\n",
              " 515,\n",
              " 17,\n",
              " 12,\n",
              " 16,\n",
              " 626,\n",
              " 18,\n",
              " 19193,\n",
              " 5,\n",
              " 62,\n",
              " 386,\n",
              " 12,\n",
              " 8,\n",
              " 316,\n",
              " 8,\n",
              " 106,\n",
              " 5,\n",
              " 4,\n",
              " 2223,\n",
              " 5244,\n",
              " 16,\n",
              " 480,\n",
              " 66,\n",
              " 3785,\n",
              " 33,\n",
              " 4,\n",
              " 130,\n",
              " 12,\n",
              " 16,\n",
              " 38,\n",
              " 619,\n",
              " 5,\n",
              " 25,\n",
              " 124,\n",
              " 51,\n",
              " 36,\n",
              " 135,\n",
              " 48,\n",
              " 25,\n",
              " 1415,\n",
              " 33,\n",
              " 6,\n",
              " 22,\n",
              " 12,\n",
              " 215,\n",
              " 28,\n",
              " 77,\n",
              " 52,\n",
              " 5,\n",
              " 14,\n",
              " 407,\n",
              " 16,\n",
              " 82,\n",
              " 10311,\n",
              " 8,\n",
              " 4,\n",
              " 107,\n",
              " 117,\n",
              " 5952,\n",
              " 15,\n",
              " 256,\n",
              " 4,\n",
              " 2,\n",
              " 7,\n",
              " 3766,\n",
              " 5,\n",
              " 723,\n",
              " 36,\n",
              " 71,\n",
              " 43,\n",
              " 530,\n",
              " 476,\n",
              " 26,\n",
              " 400,\n",
              " 317,\n",
              " 46,\n",
              " 7,\n",
              " 4,\n",
              " 12118,\n",
              " 1029,\n",
              " 13,\n",
              " 104,\n",
              " 88,\n",
              " 4,\n",
              " 381,\n",
              " 15,\n",
              " 297,\n",
              " 98,\n",
              " 32,\n",
              " 2071,\n",
              " 56,\n",
              " 26,\n",
              " 141,\n",
              " 6,\n",
              " 194,\n",
              " 7486,\n",
              " 18,\n",
              " 4,\n",
              " 226,\n",
              " 22,\n",
              " 21,\n",
              " 134,\n",
              " 476,\n",
              " 26,\n",
              " 480,\n",
              " 5,\n",
              " 144,\n",
              " 30,\n",
              " 5535,\n",
              " 18,\n",
              " 51,\n",
              " 36,\n",
              " 28,\n",
              " 224,\n",
              " 92,\n",
              " 25,\n",
              " 104,\n",
              " 4,\n",
              " 226,\n",
              " 65,\n",
              " 16,\n",
              " 38,\n",
              " 1334,\n",
              " 88,\n",
              " 12,\n",
              " 16,\n",
              " 283,\n",
              " 5,\n",
              " 16,\n",
              " 4472,\n",
              " 113,\n",
              " 103,\n",
              " 32,\n",
              " 15,\n",
              " 16,\n",
              " 5345,\n",
              " 19,\n",
              " 178,\n",
              " 32]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "JhI3qZXHExw-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "here our work is already simplified as we are not suppose to deal with words ,it is already converted into vector of integers, just remember that each vector integer notifies a specific word , it is in vector integer as our model runs on integer data only."
      ]
    },
    {
      "metadata": {
        "id": "ZVMWGY0AFReN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2d680ae3-5edb-4e03-98fb-eaae8c610f80"
      },
      "cell_type": "code",
      "source": [
        "y_train[0]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "gu_fRyfEFUWy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "here the lable is binaru eithe 0 or 1 representing whether the author liked the film or not based on the review given by the auther."
      ]
    },
    {
      "metadata": {
        "id": "6htg6aXFFhTY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train=sequence.pad_sequences(x_train,maxlen=80)\n",
        "x_test=sequence.pad_sequences(x_test,maxlen=80)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IfLULs1AINeR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "review of the movie could be of varying length hence we consider max length of 80 for sentiment analysis."
      ]
    },
    {
      "metadata": {
        "id": "EB14AVYRIapM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "lets prepare our model."
      ]
    },
    {
      "metadata": {
        "id": "RE521xXIIYz1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model= Sequential()\n",
        "model.add(Embedding(20000,128))\n",
        "model.add(LSTM(128,dropout=0.2,recurrent_dropout=0.2))\n",
        "model.add(Dense(1,activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FbYsy9q_Kh_k",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Embedding layer converts the input data into dense fixed size vector suited for the neural network. 20000 is the size of the vocabulary and 128 is the output dimension of 128 units."
      ]
    },
    {
      "metadata": {
        "id": "TkvyUu6vLI6U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sFvtZ4S9LXOL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        },
        "outputId": "8c432e25-cb57-4fee-b9c0-8347d20080bc"
      },
      "cell_type": "code",
      "source": [
        "model.fit(x_train,y_train,batch_size=32,epochs=16,verbose=2,\n",
        "          validation_data=(x_test,y_test))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 25000 samples, validate on 25000 samples\n",
            "Epoch 1/16\n",
            " - 158s - loss: 0.4664 - acc: 0.7820 - val_loss: 0.3826 - val_acc: 0.8313\n",
            "Epoch 2/16\n",
            " - 156s - loss: 0.2996 - acc: 0.8790 - val_loss: 0.4173 - val_acc: 0.8234\n",
            "Epoch 3/16\n",
            " - 158s - loss: 0.2130 - acc: 0.9180 - val_loss: 0.4054 - val_acc: 0.8335\n",
            "Epoch 4/16\n",
            " - 156s - loss: 0.1488 - acc: 0.9444 - val_loss: 0.4898 - val_acc: 0.8206\n",
            "Epoch 5/16\n",
            " - 156s - loss: 0.1096 - acc: 0.9605 - val_loss: 0.5584 - val_acc: 0.8230\n",
            "Epoch 6/16\n",
            " - 153s - loss: 0.0763 - acc: 0.9729 - val_loss: 0.6276 - val_acc: 0.8224\n",
            "Epoch 7/16\n",
            " - 155s - loss: 0.0507 - acc: 0.9837 - val_loss: 0.7103 - val_acc: 0.8077\n",
            "Epoch 8/16\n",
            " - 154s - loss: 0.0437 - acc: 0.9855 - val_loss: 0.7587 - val_acc: 0.8167\n",
            "Epoch 9/16\n",
            " - 153s - loss: 0.0309 - acc: 0.9894 - val_loss: 0.8874 - val_acc: 0.8166\n",
            "Epoch 10/16\n",
            " - 154s - loss: 0.0242 - acc: 0.9920 - val_loss: 0.9208 - val_acc: 0.8148\n",
            "Epoch 11/16\n",
            " - 155s - loss: 0.0169 - acc: 0.9950 - val_loss: 0.8752 - val_acc: 0.8123\n",
            "Epoch 12/16\n",
            " - 153s - loss: 0.0181 - acc: 0.9942 - val_loss: 1.0126 - val_acc: 0.8129\n",
            "Epoch 13/16\n",
            " - 154s - loss: 0.0140 - acc: 0.9956 - val_loss: 1.0423 - val_acc: 0.8070\n",
            "Epoch 14/16\n",
            " - 154s - loss: 0.0116 - acc: 0.9963 - val_loss: 1.0022 - val_acc: 0.8071\n",
            "Epoch 15/16\n",
            " - 156s - loss: 0.0099 - acc: 0.9969 - val_loss: 1.0395 - val_acc: 0.8070\n",
            "Epoch 16/16\n",
            " - 155s - loss: 0.0069 - acc: 0.9981 - val_loss: 1.1428 - val_acc: 0.8100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb5d0152f60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "aqyS50WKbdVa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "score=model.evaluate(x_test,y_test,batch_size=32,verbose=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F25FnK0ybypZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "d3fd9c99-e564-4c2c-b4ab-198ca3070ff7"
      },
      "cell_type": "code",
      "source": [
        "print('loss:',score[0])\n",
        "print('accuracy:',score[1])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss: 1.1427973308932782\n",
            "accuracy: 0.81\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}